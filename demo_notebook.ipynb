{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# MCP Demo with RAG - Colab Adaptation\n",
                "\n",
                "This notebook demonstrates the core concepts of the Model Context Protocol (MCP) with Retrieval-Augmented Generation (RAG), adapted from the [MCP Demo](https://github.com/thinklytics/mcp-demo).\n",
                "\n",
                "It simulates an MCP server's tools (including RAG) as Python functions and shows how a client can interact with them.\n",
                "\n",
                "**Note:** This version uses direct function calls, not actual network protocols (like MCP's stdio/SSE), for simplicity in Colab."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Data Models\n",
                "\n",
                "Install necessary libraries and define Pydantic models for structured data exchange (adapted from `models.py`)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
                        "Note: you may need to restart the kernel to use updated packages.\n",
                        "✅ Libraries installed and Models defined.\n"
                    ]
                }
            ],
            "source": [
                "%pip install pydantic -q\n",
                "\n",
                "from pydantic import BaseModel, Field\n",
                "from typing import List, Dict, Any, Optional\n",
                "from datetime import datetime\n",
                "from enum import Enum\n",
                "\n",
                "class DocumentMetadata(BaseModel):\n",
                "    source: Optional[str] = None\n",
                "    topic: Optional[str] = None\n",
                "    created_at: Optional[str] = Field(default_factory=lambda: datetime.now().isoformat())\n",
                "    class Config: extra = 'allow'\n",
                "\n",
                "class DocumentStatus(str, Enum):\n",
                "    SUCCESS = \"success\"; ERROR = \"error\"; DUPLICATE = \"duplicate\"\n",
                "\n",
                "class Document(BaseModel):\n",
                "    id: str; preview: str; metadata: Optional[DocumentMetadata] = None\n",
                "\n",
                "class SearchResult(BaseModel):\n",
                "    document: str; score: float; metadata: Optional[DocumentMetadata] = None\n",
                "\n",
                "class AddDocumentRequest(BaseModel):\n",
                "    content: str; metadata: Optional[Dict[str, Any]] = None\n",
                "\n",
                "class AddDocumentResponse(BaseModel):\n",
                "    status: DocumentStatus; id: Optional[str] = None; message: Optional[str] = None\n",
                "\n",
                "class SearchRequest(BaseModel):\n",
                "    query: str; top_k: int = 3\n",
                "\n",
                "print(\"✅ Libraries installed and Models defined.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Simulate Server-Side Logic (Tools)\n",
                "\n",
                "Define Python functions that mimic the MCP server's tools, using a simple in-memory dictionary for the RAG knowledge base."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✅ Simulated Server Tools Defined.\n"
                    ]
                }
            ],
            "source": [
                "import json\n",
                "from datetime import datetime\n",
                "\n",
                "# Simulate the in-memory document store\n",
                "in_memory_docs: Dict[str, Dict[str, Any]] = {}\n",
                "\n",
                "# --- Tool Definitions ---\n",
                "\n",
                "def echo(message: str) -> str:\n",
                "    # print(f\"--- Tool: echo(message='{message}') ---\")\n",
                "    return f\"Echo: {message}\"\n",
                "\n",
                "def add(a: float, b: float) -> float:\n",
                "    # print(f\"--- Tool: add(a={a}, b={b}) ---\")\n",
                "    return a + b\n",
                "\n",
                "def _check_for_duplicate_document(content: str):\n",
                "    for doc_id, doc_data in in_memory_docs.items():\n",
                "        if doc_data.get(\"content\") == content: return True, doc_id\n",
                "    return False, None\n",
                "\n",
                "def add_document(content: str, metadata: Dict[str, Any] = None) -> Dict[str, Any]:\n",
                "    # print(f\"--- Tool: add_document(content='...', metadata={metadata}) ---\")\n",
                "    try:\n",
                "        metadata = metadata or {}\n",
                "        validated_meta = DocumentMetadata(**metadata)\n",
                "        metadata_dict = validated_meta.model_dump(exclude_none=True)\n",
                "        exists, duplicate_id = _check_for_duplicate_document(content)\n",
                "        if exists:\n",
                "            response = AddDocumentResponse(status=DocumentStatus.DUPLICATE, id=duplicate_id,\n",
                "                                         message=f\"Duplicate content. Exists as ID: {duplicate_id}\")\n",
                "        else:\n",
                "            doc_id = f\"doc_{len(in_memory_docs) + 1}\"\n",
                "            in_memory_docs[doc_id] = {\"content\": content, \"metadata\": metadata_dict}\n",
                "            response = AddDocumentResponse(status=DocumentStatus.SUCCESS, id=doc_id)\n",
                "        return response.model_dump()\n",
                "    except Exception as e:\n",
                "        return AddDocumentResponse(status=DocumentStatus.ERROR, message=str(e)).model_dump()\n",
                "\n",
                "def list_documents() -> List[Dict[str, Any]]:\n",
                "    # print(\"--- Tool: list_documents() ---\")\n",
                "    results = []\n",
                "    for doc_id, doc_data in in_memory_docs.items():\n",
                "        content = doc_data.get(\"content\", \"\")\n",
                "        preview = content[:80] + \"...\" if len(content) > 80 else content\n",
                "        metadata_obj = DocumentMetadata(**doc_data.get(\"metadata\", {}))\n",
                "        doc = Document(id=doc_id, preview=preview, metadata=metadata_obj)\n",
                "        results.append(doc.model_dump(exclude_none=True))\n",
                "    return results\n",
                "\n",
                "def rag_search(query: str, top_k: int = 3) -> List[Dict[str, Any]]:\n",
                "    # print(f\"--- Tool: rag_search(query='{query}', top_k={top_k}) ---\")\n",
                "    query_terms = query.lower().split()\n",
                "    matches = []\n",
                "    for doc_id, doc_data in in_memory_docs.items():\n",
                "        content = doc_data.get(\"content\", \"\").lower()\n",
                "        score = sum(1 for term in query_terms if term in content) / len(query_terms) if query_terms else 0\n",
                "        if score > 0:\n",
                "            metadata_obj = DocumentMetadata(**doc_data.get(\"metadata\", {}))\n",
                "            search_res = SearchResult(document=doc_data.get(\"content\", \"\"), metadata=metadata_obj, score=score)\n",
                "            matches.append(search_res.model_dump(exclude_none=True))\n",
                "\n",
                "    matches.sort(key=lambda x: x[\"score\"], reverse=True)\n",
                "    results = matches[:top_k]\n",
                "    if not results:\n",
                "         return [SearchResult(document=\"No relevant documents found\", metadata=None, score=0.0).model_dump()]\n",
                "    return results\n",
                "\n",
                "# Simulate the sample data resource\n",
                "SAMPLE_DATA = \"This is sample data.\\nIt contains multiple lines.\"\n",
                "def read_resource(uri: str) -> str:\n",
                "    # print(f\"--- Resource: read_resource(uri='{uri}') ---\")\n",
                "    return SAMPLE_DATA if uri == \"sample://data\" else f\"Resource not found: {uri}\"\n",
                "\n",
                "print(\"✅ Simulated Server Tools Defined.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Client Test Helper\n",
                "\n",
                "A helper function to parse the simulated dictionary responses back into Pydantic models for easier handling on the 'client' side."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✅ Client Helper Defined.\n"
                    ]
                }
            ],
            "source": [
                "# Helper function to parse responses\n",
                "def parse_simulated_response(response_data: Any, model_class: type) -> Any:\n",
                "    \"\"\"Parses simulated tool response (dict/list) into Pydantic models.\"\"\"\n",
                "    try:\n",
                "        if isinstance(response_data, list):\n",
                "            return [model_class(**item) for item in response_data]\n",
                "        elif isinstance(response_data, dict):\n",
                "            return model_class(**response_data)\n",
                "        elif isinstance(response_data, (str, int, float, bool)):\n",
                "             return response_data # Primitive types\n",
                "        else:\n",
                "            print(f\"Warning: Unexpected response type: {type(response_data)}.\")\n",
                "            return response_data\n",
                "    except Exception as e:\n",
                "        print(f\"Error parsing response into {model_class.__name__}: {e}\")\n",
                "        return None if isinstance(response_data, dict) else []\n",
                "\n",
                "print(\"✅ Client Helper Defined.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Client Interaction Tests\n",
                "\n",
                "These cells simulate a client calling the server's tools. Run them sequentially."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.1 Test Basic Tools (Echo, Add)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Testing Basic Tools ---\n",
                        "Echo Result: Echo: Hello from Colab!\n",
                        "Add Result: 22.5\n"
                    ]
                }
            ],
            "source": [
                "print(\"--- Testing Basic Tools ---\")\n",
                "echo_resp = echo(message=\"Hello from Colab!\")\n",
                "print(f\"Echo Result: {parse_simulated_response(echo_resp, str)}\")\n",
                "\n",
                "add_resp = add(a=15, b=7.5)\n",
                "print(f\"Add Result: {parse_simulated_response(add_resp, float)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.2 Test Adding Documents"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Testing Add Document ---\n",
                        "Add Status: DocumentStatus.SUCCESS, ID: doc_1, Msg: None\n",
                        "Add Status: DocumentStatus.SUCCESS, ID: doc_2, Msg: None\n",
                        "Add Status: DocumentStatus.SUCCESS, ID: doc_3, Msg: None\n",
                        "\n",
                        "Testing duplicate add:\n",
                        "Add Status: DocumentStatus.DUPLICATE, ID: doc_1, Msg: Duplicate content. Exists as ID: doc_1\n"
                    ]
                }
            ],
            "source": [
                "print(\"--- Testing Add Document ---\")\n",
                "# Clear any previous docs for clean test run\n",
                "in_memory_docs.clear()\n",
                "\n",
                "docs_to_add = [\n",
                "    {\"content\": \"MCP allows AI models to interact with external tools.\", \"metadata\": {\"topic\": \"MCP\"}},\n",
                "    {\"content\": \"RAG combines LLMs with information retrieval.\", \"metadata\": {\"topic\": \"RAG\"}},\n",
                "    {\"content\": \"Thinklytics focuses on strategic thinking and data analytics for decision making.\", \"metadata\": {\"topic\": \"Blog\"}}\n",
                "]\n",
                "\n",
                "for doc in docs_to_add:\n",
                "    add_raw = add_document(content=doc[\"content\"], metadata=doc[\"metadata\"])\n",
                "    add_resp = parse_simulated_response(add_raw, AddDocumentResponse)\n",
                "    if add_resp: print(f\"Add Status: {add_resp.status}, ID: {add_resp.id}, Msg: {add_resp.message}\")\n",
                "\n",
                "# Test duplicate\n",
                "print(\"\\nTesting duplicate add:\")\n",
                "add_dup_raw = add_document(content=docs_to_add[0][\"content\"], metadata=docs_to_add[0][\"metadata\"])\n",
                "add_dup_resp = parse_simulated_response(add_dup_raw, AddDocumentResponse)\n",
                "if add_dup_resp: print(f\"Add Status: {add_dup_resp.status}, ID: {add_dup_resp.id}, Msg: {add_dup_resp.message}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.3 Test Listing Documents"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Testing List Documents ---\n",
                        "Found 3 documents:\n",
                        "- ID: doc_1, Preview: 'MCP allows AI models to interact with external tools.', Meta: [topic=MCP, created_at=2025-04-11T18:48:42.008682]\n",
                        "- ID: doc_2, Preview: 'RAG combines LLMs with information retrieval.', Meta: [topic=RAG, created_at=2025-04-11T18:48:42.008754]\n",
                        "- ID: doc_3, Preview: 'Thinklytics focuses on data analytics for decision making.', Meta: [topic=Blog, created_at=2025-04-11T18:48:42.008786]\n"
                    ]
                }
            ],
            "source": [
                "print(\"--- Testing List Documents ---\")\n",
                "list_raw = list_documents()\n",
                "documents = parse_simulated_response(list_raw, Document)\n",
                "\n",
                "if not documents:\n",
                "    print(\"No documents found.\")\n",
                "else:\n",
                "    print(f\"Found {len(documents)} documents:\")\n",
                "    for doc in documents:\n",
                "        meta_str = \", \".join([f\"{k}={v}\" for k, v in doc.metadata.model_dump(exclude_none=True).items()])\n",
                "        print(f\"- ID: {doc.id}, Preview: '{doc.preview}', Meta: [{meta_str}]\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.4 Test RAG Search"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Testing RAG Search ---\n",
                        "Search results for 'What is MCP?':\n",
                        "- Doc: 'Thinklytics focuses on data analytics for decision...', Score: 0.33, Meta: [topic=Blog, created_at=2025-04-11T18:48:42.008786]\n"
                    ]
                }
            ],
            "source": [
                "print(\"--- Testing RAG Search ---\")\n",
                "search_query = \"What is MCP?\"\n",
                "search_req = SearchRequest(query=search_query, top_k=2)\n",
                "search_raw = rag_search(query=search_req.query, top_k=search_req.top_k)\n",
                "search_results = parse_simulated_response(search_raw, SearchResult)\n",
                "\n",
                "print(f\"Search results for '{search_query}':\")\n",
                "if not search_results or (len(search_results) == 1 and search_results[0].document == \"No relevant documents found\"):\n",
                "    print(\"No relevant documents found.\")\n",
                "else:\n",
                "    for item in search_results:\n",
                "        meta_str = \", \".join([f\"{k}={v}\" for k, v in item.metadata.model_dump(exclude_none=True).items()]) if item.metadata else \"None\"\n",
                "        print(f\"- Doc: '{item.document[:50]}...', Score: {item.score:.2f}, Meta: [{meta_str}]\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.5 Test Reading Resource"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Testing Read Resource ---\n",
                        "Content of resource 'sample://data':\n",
                        "This is sample data.\n",
                        "It contains multiple lines.\n"
                    ]
                }
            ],
            "source": [
                "print(\"--- Testing Read Resource ---\")\n",
                "resource_uri = \"sample://data\"\n",
                "resource_raw = read_resource(resource_uri)\n",
                "resource_data = parse_simulated_response(resource_raw, str)\n",
                "print(f\"Content of resource '{resource_uri}':\\n{resource_data}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Conclusion\n",
                "\n",
                "This notebook simulated the MCP RAG demo flow:\n",
                "1. Defined data models (Pydantic).\n",
                "2. Implemented server-side tools (Python functions) with in-memory RAG.\n",
                "3. Executed client-side calls to test adding, listing, searching (RAG), and resource access.\n",
                "\n",
                "This illustrates how MCP enables structured interaction between AI models and external capabilities, even without the network layer."
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
